{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import calculate_mse\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/test.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "N = tX.shape[0]\n",
    "# add column of ones to add bias term\n",
    "tx = np.hstack((np.ones((N, 1)), tX))\n",
    "\n",
    "D = tX.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# use only outlier-free data for plotting\n",
    "tX_plot = np.array([row for row in tX if -999. not in row])\n",
    "tX_plot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NAs are marked as -999\n",
    "print(\"tX.head = \", tX[:5,:5])\n",
    "#print(tX[:5,5:10])\n",
    "#print(tX[:5,10:15])\n",
    "print(\"tX.shape = \",tX.shape)\n",
    "print(\"tX.size = \", tX.size, \"\\n\")\n",
    "\n",
    "print(\"y.head = \",y[:10])\n",
    "\n",
    "print(np.where(y == -1))\n",
    "print(np.unique(y))\n",
    "print(\"y.shape = \",y.shape)\n",
    "print(\"y.size = \", y.size, \"\\n\")\n",
    "\n",
    "print(\"ids.head = \",ids[:10])\n",
    "print(\"ids.shape = \", ids.shape)\n",
    "print(\"ids.size = \", ids.size, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "ax1.boxplot(tX[:100,:15]);\n",
    "ax2.boxplot(tX[:100,15:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(tX_plot[:100,:1], bins = 100, histtype='step', stacked=True, fill=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Do your crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize dataset\n",
    "for indx_col in range(tX.shape[1]):\n",
    "    tX[:, indx_col] = (tX[:, indx_col] - np.mean(tX[:, indx_col]))/np.std(tX[:, indx_col])\n",
    "\n",
    "print(y)\n",
    "# Split dataset\n",
    "split_perc = 0.7\n",
    "split_ind = int(len(y) * split_perc)\n",
    "\n",
    "# Training set\n",
    "y_train = y[:split_ind]\n",
    "tX_train = tX[:split_ind]\n",
    "ids_train = ids[:split_ind]\n",
    "\n",
    "# Validation set\n",
    "y_val = y[split_ind:]\n",
    "tX_val = tX[split_ind:]\n",
    "ids_val = ids[split_ind:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "max_iters = 100\n",
    "gamma = 0.01\n",
    "lambda_ = 0.1\n",
    "\n",
    "# Initialize weights\n",
    "initial_w = np.random.rand(D,)\n",
    "\n",
    "from implementations import *\n",
    "# Train\n",
    "#weights_ls_GD, loss_ls_GD = least_squares_GD(y_train, tX_train, initial_w, max_iters, gamma)\n",
    "#print(loss_ls_GD)\n",
    "#weights_ls_SGD, loss_ls_SGD = least_squares_SGD(y_train, tX_train, initial_w, max_iters, gamma)\n",
    "#weights_ls, loss_ls = least_squares(y_train, tX_train)\n",
    "# weights_rr, loss_rr = ridge_regression(y_train, tX_train, lambda_)\n",
    "# weights_lr, loss_lr = logistic_regression(y_train, tX_train, initial_w, max_iters, gamma)\n",
    "# weights_reg_lr, loss_reg_lr = reg_logistic_regression(y_train, tX_train, lambda_, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import cross_validation, build_k_indices\n",
    "# Cross-validation\n",
    "\n",
    "k = 5\n",
    "k_indices = build_k_indices(y, k)\n",
    "ls_GD_losses = []\n",
    "ls_losses = []\n",
    "\n",
    "for k_iteration in range(k):\n",
    "    tX_train, y_train, tX_val, y_val = cross_validation(y, tX, k_indices, k_iteration)\n",
    "    weights_ls_GD, loss_ls_GD = least_squares_GD(y_train, tX_train, initial_w, max_iters, gamma)\n",
    "    weights_ls, loss_ls = least_squares(y_train, tX_train)\n",
    "\n",
    "    y_pred_ls_GD_val = tX_val @ weights_ls_GD\n",
    "    y_pred_ls_val = tX_val @ weights_ls\n",
    "\n",
    "    ls_GD_losses.append(calculate_mse_loss(y_val, y_pred_ls_val))\n",
    "    ls_losses.append(calculate_mse_loss(y_val, y_pred_ls_val))\n",
    "\n",
    "ls_GD_losses = np.array(ls_GD_losses)\n",
    "ls_losses = np.array(ls_losses)\n",
    "\n",
    "ls_GD_mean_loss = np.mean(ls_GD_losses)\n",
    "ls_mean_loss = np.mean(ls_losses)\n",
    "\n",
    "print(ls_GD_mean_loss, ls_mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate predictions and save output in csv format for submission:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: decide real weights\n",
    "weights = least_squares_GD(y, tX, initial_w, max_iters, gamma)\n",
    "OUTPUT_PATH = '../data/submission.csv'\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}