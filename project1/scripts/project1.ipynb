{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/test.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Do your crazy machine learning thing here :) ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Exploratory data analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Normalize dataset\n",
    "\n",
    "# Split dataset\n",
    "split_perc = 0.7\n",
    "split_ind = int(len(y) * split_perc)\n",
    "\n",
    "# Training set\n",
    "y_train = y[:split_ind]\n",
    "tX_train = tX[:split_ind]\n",
    "ids_train = ids[:split_ind]\n",
    "\n",
    "# Validation set\n",
    "y_val = y[split_ind:]\n",
    "tX_val = tX[split_ind:]\n",
    "ids_val = ids[split_ind:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavi_oliva/Documents/EPFL/Projects/epfl_ml/project1/scripts/implementations.py:12: RuntimeWarning: overflow encountered in matmul\n",
      "  grad = -tx.T @ err / len(err)\n",
      "/home/xavi_oliva/Documents/EPFL/Projects/epfl_ml/project1/scripts/implementations.py:11: RuntimeWarning: invalid value encountered in matmul\n",
      "  err = y - tx @ w\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters\n",
    "\n",
    "max_iters = 100\n",
    "gamma = 0.01\n",
    "lambda_ = 0.1\n",
    "\n",
    "# Initialize weights\n",
    "initial_w = np.random.rand(tX.shape[1],)\n",
    "\n",
    "from implementations import *\n",
    "# Train\n",
    "weights_ls_GD, loss_ls_GD = least_squares_GD(y_train, tX_train, initial_w, max_iters, gamma)\n",
    "# weights_ls_SGD, loss_ls_SGD = least_squares_SGD(y_train, tX_train, initial_w, max_iters, gamma)\n",
    "weights_ls, loss_ls = least_squares(y_train, tX_train)\n",
    "# weights_rr, loss_rr = ridge_regression(y_train, tX_train, lambda_)\n",
    "# weights_lr, loss_lr = logistic_regression(y_train, tX_train, initial_w, max_iters, gamma)\n",
    "# weights_reg_lr, loss_reg_lr = reg_logistic_regression(y_train, tX_train, lambda_, initial_w, max_iters, gamma)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "weights = weights_ls_GD\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save output in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-31-b84bab86d277>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mOUTPUT_PATH\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'../data/submission.csv'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpredict_labels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweights\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mcreate_csv_submission\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mids_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mOUTPUT_PATH\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/EPFL/Projects/epfl_ml/project1/scripts/proj1_helpers.py\u001B[0m in \u001B[0;36mcreate_csv_submission\u001B[0;34m(ids, y_pred, name)\u001B[0m\n\u001B[1;32m     46\u001B[0m         \u001B[0mwriter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwriteheader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mr1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mr2\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m             \u001B[0mwriter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwriterow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m'Id'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mr1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Prediction'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mr2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '../data/submission.csv'\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}