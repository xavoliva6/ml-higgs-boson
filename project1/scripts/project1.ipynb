{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import calculate_mse\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "N = tX.shape[0]\n",
    "# add column of ones to add bias term\n",
    "tx = np.hstack((np.ones((N, 1)), tX))\n",
    "\n",
    "D = tX.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## 1. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "ax1.boxplot(tX[:100,:15]);\n",
    "ax2.boxplot(tX[:100,15:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# boxplots of standardized features\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(tX_plot_stand [:,]);\n",
    "ax.set_xticklabels(np.arange(0,30,1));\n",
    "ax.set_xlabel(\"Features\");\n",
    "ax.set_ylabel(\"Standardized Values\");\n",
    "ax.set_title(\"Boxplot of standardized features\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices sorted by variance of unstandardized trainings data\n",
    "s = np.std(tX_plot , axis = 0)\n",
    "s = np.argsort(s).tolist()\n",
    "\n",
    "# feature 12 in [0,1]\n",
    "# feature 22 in {2,3}\n",
    "# feature 14, 17 in [-2.5, 2.5]\n",
    "# feature 20, 18, 25 in [-3.142, 3.142]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms of features\n",
    "fig, ((ax1, ax2), (ax3,ax4)) = plt.subplots(2,2)\n",
    "ax1.hist(tX_plot[:,s[:5]], bins = 100, histtype='step', stacked=True, fill=False);\n",
    "ax2.hist(tX_plot[:,s[5:15]], bins = 100, histtype='step', stacked=True, fill=False);\n",
    "ax3.hist(tX_plot[:,s[15:25]], bins = 100, histtype='step', stacked=True, fill=False);\n",
    "ax4.hist(tX_plot[:,s[25:]], bins = 100, histtype='step', stacked=True, fill=False);\n",
    "ax1.set_title(\"Histogram of unstandardized features\");\n",
    "# find a faster way to freshen up plot\n",
    "\n",
    "ax1.set_yticklabels([]);\n",
    "ax2.set_yticklabels([]);\n",
    "ax3.set_yticklabels([]);\n",
    "ax4.set_yticklabels([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize dataset\n",
    "for indx_col in range(tX.shape[1]):\n",
    "    tX[:, indx_col] = (tX[:, indx_col] - np.mean(tX[:, indx_col]))/np.std(tX[:, indx_col])\n",
    "\n",
    "print(y)\n",
    "# Split dataset\n",
    "split_perc = 0.7\n",
    "split_ind = int(len(y) * split_perc)\n",
    "\n",
    "# Training set\n",
    "y_train = y[:split_ind]\n",
    "tX_train = tX[:split_ind]\n",
    "ids_train = ids[:split_ind]\n",
    "\n",
    "# Validation set\n",
    "y_val = y[split_ind:]\n",
    "tX_val = tX[split_ind:]\n",
    "ids_val = ids[split_ind:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "max_iters = 100\n",
    "gamma = 0.01\n",
    "lambda_ = 0.1\n",
    "\n",
    "# Initialize weights\n",
    "initial_w = np.random.rand(D,)\n",
    "\n",
    "from implementations import *\n",
    "# Train\n",
    "#weights_ls_GD, loss_ls_GD = least_squares_GD(y_train, tX_train, initial_w, max_iters, gamma)\n",
    "#print(loss_ls_GD)\n",
    "#weights_ls_SGD, loss_ls_SGD = least_squares_SGD(y_train, tX_train, initial_w, max_iters, gamma)\n",
    "#weights_ls, loss_ls = least_squares(y_train, tX_train)\n",
    "# weights_rr, loss_rr = ridge_regression(y_train, tX_train, lambda_)\n",
    "# weights_lr, loss_lr = logistic_regression(y_train, tX_train, initial_w, max_iters, gamma)\n",
    "# weights_reg_lr, loss_reg_lr = reg_logistic_regression(y_train, tX_train, lambda_, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import cross_validation, build_k_indices\n",
    "# Cross-validation\n",
    "\n",
    "k = 5\n",
    "k_indices = build_k_indices(y, k)\n",
    "ls_GD_losses = []\n",
    "ls_losses = []\n",
    "\n",
    "for k_iteration in range(k):\n",
    "    tX_train, y_train, tX_val, y_val = cross_validation(y, tX, k_indices, k_iteration)\n",
    "    weights_ls_GD, loss_ls_GD = least_squares_GD(y_train, tX_train, initial_w, max_iters, gamma)\n",
    "    weights_ls, loss_ls = least_squares(y_train, tX_train)\n",
    "\n",
    "    y_pred_ls_GD_val = tX_val @ weights_ls_GD\n",
    "    y_pred_ls_val = tX_val @ weights_ls\n",
    "\n",
    "    ls_GD_losses.append(calculate_mse_loss(y_val, y_pred_ls_val))\n",
    "    ls_losses.append(calculate_mse_loss(y_val, y_pred_ls_val))\n",
    "\n",
    "ls_GD_losses = np.array(ls_GD_losses)\n",
    "ls_losses = np.array(ls_losses)\n",
    "\n",
    "ls_GD_mean_loss = np.mean(ls_GD_losses)\n",
    "ls_mean_loss = np.mean(ls_losses)\n",
    "\n",
    "print(ls_GD_mean_loss, ls_mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save output in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: decide real weights\n",
    "weights = least_squares_GD(y, tX, initial_w, max_iters, gamma)\n",
    "OUTPUT_PATH = '../data/submission.csv'\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
